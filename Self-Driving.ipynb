{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-values are initialized to an arbitrary value, and as the agent exposes itself to the environment and receives different rewards by executing different actions, the Q-values are updated using the equation:\n",
    "\n",
    "***Q(state,action)←(1−α)Q(state,action)+α(reward+γmaxaQ(next state,all actions))***\n",
    "\n",
    "Where:\n",
    "\n",
    "- α (alpha) is the learning rate (0<α≤1) - Just like in supervised learning settings, α is the extent to which our Q-values are being updated in every iteration.\n",
    "\n",
    "- γ (gamma) is the discount factor (0≤γ≤1) - determines how much importance we want to give to future rewards. A high value for the discount factor (close to 1) captures the long-term effective award, whereas, a discount factor of 0 makes our agent consider only immediate reward, hence making it greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[43m \u001b[0m| : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| :\u001b[43m \u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "env.reset() # reset environment to a new, random state\n",
    "env.render()\n",
    "\n",
    "print(\"Action Space {}\".format(env.action_space))\n",
    "print(\"State Space {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **blue** letter represents the current passenger *pick-up location*, and the **purple** letter is the *current destination*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n",
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(3, 1, 2, 0) # (taxi row, taxi column, passenger index, destination index)\n",
    "print(\"State:\", state)\n",
    "\n",
    "env.s = state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Taxi environment is created, there is an initial Reward table that's also created, called `P`. We can think of it like a matrix that has the **number of states as rows and number of actions as columns**, i.e. a **states × actions** matrix.\n",
    "\n",
    "This dictionary has the structure {action: [(probability, nextstate, reward, done)]}\n",
    "\n",
    "0-5 corresponds to the actions (south, north, east, west, pickup, dropoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, -1, False, {'prob': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 328, -1, False)],\n",
       " 2: [(1.0, 448, -1, False)],\n",
       " 3: [(1.0, 428, -1, False)],\n",
       " 4: [(1.0, 428, -10, False)],\n",
       " 5: [(1.0, 428, -10, False)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, -1, False, {'prob': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRUTE FORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 483\n",
      "Penalties incurred: 165\n"
     ]
    }
   ],
   "source": [
    "env.s = 328  # set environment to illustration's state\n",
    "\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "\n",
    "frames = [] # for animation\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    if reward == -10:\n",
    "        penalties += 1\n",
    "    \n",
    "    # Put each rendered frame into dict for animation\n",
    "    frames = [] \n",
    "    frames.append({\n",
    "        'frame': env.render(mode='ansi'),\n",
    "        'state': state,\n",
    "        'action': action,\n",
    "        'reward': reward\n",
    "        }\n",
    "    )\n",
    "\n",
    "    epochs += 1\n",
    "    \n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Penalties incurred: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n",
      "Timestep: 1\n",
      "State: 0\n",
      "Action: 5\n",
      "Reward: 20\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(.1)\n",
    "        \n",
    "print_frames(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100000\n",
      "Training finished.\n",
      "\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"Training the agent\"\"\"\n",
    "\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "for i in range(1, 100001):\n",
    "    state = env.reset()\n",
    "\n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample() # Explore action space\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Exploit learned values\n",
    "\n",
    "        next_state, reward, done, info = env.step(action) \n",
    "        \n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[next_state])\n",
    "        \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[state, action] = new_value\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "            all_penalties.append(penalties)\n",
    "        else:\n",
    "            all_penalties.append(0)\n",
    "            \n",
    "\n",
    "        state = next_state\n",
    "        epochs += 1\n",
    "        all_epochs.append(epochs)\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episode: {i}\")\n",
    "\n",
    "print(\"Training finished.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n",
      "Timestep: 10\n",
      "State: 475\n",
      "Action: 5\n",
      "Reward: 20\n",
      "Epoch No.: 1272\n",
      "\n",
      "Results after 100 episodes:\n",
      "Average timesteps per episode: 12.97\n",
      "Average penalties per episode: 0.0\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
    "\n",
    "total_epochs, total_penalties = 0, 0\n",
    "episodes = 100\n",
    "\n",
    "for _ in range(episodes):\n",
    "    state = env.reset()\n",
    "    epochs, penalties, reward = 0, 0, 0\n",
    "    \n",
    "    done = False\n",
    "    frames = []\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state])\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "        \n",
    "        frames.append({\n",
    "            'frame': env.render(mode='ansi'),\n",
    "            'state': state,\n",
    "            'action': action,\n",
    "            'reward': reward\n",
    "            }\n",
    "        )\n",
    "        epochs += 1\n",
    "    if total_epochs%4 == 0:\n",
    "        for i, frame in enumerate(frames):\n",
    "            clear_output(wait=True)\n",
    "            print(frame['frame'])\n",
    "            print(f\"Timestep: {i + 1}\")\n",
    "            print(f\"State: {frame['state']}\")\n",
    "            print(f\"Action: {frame['action']}\")\n",
    "            print(f\"Reward: {frame['reward']}\")\n",
    "            print(f\"Epoch No.: {total_epochs}\")\n",
    "            sleep(.1)\n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_epochs += epochs\n",
    "    \n",
    "print()\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / episodes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cbf23becc8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXQc1Z0v8O8vttkSGCAYHmGJCMPkxeRNyIzhkCGLA2HNvMA7M+E5vBCyMJ5hYA6ZyTtgYBIIjB87hITVYBtjVofNgMELXvC+yDu2ZUu2ZEu2bG1Yi2Wt/Xt/dEluSd1SVXdV33urv59zdNRd669b6l/d/tWtW6KqICKiePmc6QCIiCh8TO5ERDHE5E5EFENM7kREMcTkTkQUQ8NNBwAAJ510khYVFZkOg4jIKWvWrKlT1ZHp5lmR3IuKilBcXGw6DCIip4jIrkzzWJYhIoohJnciohhiciciiiEmdyKiGGJyJyKKISZ3IqIYYnInIoohJnciIkM+2lSN+pb2SLbN5E5EZMCczftw0ytrceNL0VzAyeRORBSRacsrMOvT6rTzxk1bAwCo+uxQJPtmcici8uFQRzcue/wTFFc0+F7ntzM2419eXhthVJkxuRNRQVFVJBLJ24vOL9mPovEzUeej7l2yrwnb97fgvplbow4xFEzuRFRQxjyyEF+580MAwOQlFQCArdVNBiOKBpM7ERWMmuY27KpvNR1GXjC5E1FBqGtpx5Pzy0yHkTdWjOdORBQVVcWkJeWYtKQc1Y1tpsPJGyZ3Ioq1m15ei1mb95kOI+9YliGi2Nqyt6kgEzvA5E5EMXbLq2b6mNuAyZ2IYimRUOysO2g6DGOY3IkollaU15sOwSgmdyKKpeueXxnq9jTUrUWPvWWIKFY6uhKYuqzCdBjGMbkTUaxMXLQDj8zZHvp2JfQtRotlGSKKjenFlZEkdhcxuRNRbNz25kbTIViDyZ2IYuFP80pNh2CVIZO7iJwhIgtEZKuIbBaRW73pJ4rIXBEp9X6fkLLOHSJSJiLbROTyKF8AEREAPDqX5ZhUflruXQB+o6pfA3AhgJtFZBSA8QDmqeo5AOZ5z+HNGwvgXABXAHhaRIZFETwREQDsrG0xHYJ1hkzuqlqtqmu9x80AtgI4DcDVAKZ6i00FcI33+GoAr6tqu6qWAygDcEHYgRMR9Zi2YpfpEKwTqOYuIkUAvglgJYBTVLUaSB4AAJzsLXYagMqU1aq8af23NU5EikWkuLa2NnjkRESeKUsrTIdgHd/JXUS+AOAtAL9W1cHuSZWuO+iAi7tUdaKqjlbV0SNHjvQbBhFRH8t21JkOwUq+kruIjEAysb+iqm97k/eLyKne/FMB1HjTqwCckbL66QD2hhMuEVFfYQ8zkIlrww/46S0jACYB2Kqqj6XMeg/ADd7jGwDMSJk+VkSOFJGzAJwDYFV4IRNRITrY3oWi8TPx5+LKoRcmXy33iwBcD+BiEVnv/VwF4AEAl4pIKYBLvedQ1c0ApgPYAmAWgJtVtTuS6ImoYCwtS5ZfXlu128j+XRt+YMixZVR1CTK/rksyrDMBwIQc4iIi6mPctDUAgGOPGmE4EjfwClUisl5HV6L3sanad+xq7kREpj08u8R0CM5hciciqz05vxTPLy7vfW6q9h27mjsRkSn3f7QVz32y03QYTmLLnYisNL9kf9rE7lrt2xQmdyKyzoHWDtz+1ibTYTiNZRkiss55987NOM+12rcpbLkTkVV217cOOp9dIf1hciciq3z34QWmQ4gFJnciMm5+yX7fY7KzK6Q/rLkTkVH/8cZ6vL1uDwDg+gu/POTyrpVHTGHLnYjybn9TG86+80MUVzT0JnbbuXZQYXInorza39SG9zfsRXdC8e764Ik9zPKIOpey/WNZhojyZtmOOlz3/Eqc+6XjAADHH31E4G2YSseu1dzZcieivKhsaMWDH5X0PgbMt5zFuZTtH1vuRJQX33nocBfHI0cMA9q6DEYTnGsFHCZ3IopUIqF4eM62PtPUy5TZtJzj29YOF8syRBSpdZUH8MzCHX2miZehsynLsObuD5M7EYXu16+vw00vJ2+LV9/SbjiacLAsQ0QFp6W9CyOGCY4cPgx7DxzCu+v3Dro8yzLRY8udiHL29btnY+zEFQCAkn1NQy7Pskz0mNyJKCcLttUAANbtPmA4EkrF5E5EWSuracEvpqwOvJ6LZRnXau5M7kTkW11LOx6cVYLuRDLVldW0ZLUdF8syrmFyJ6JBNRzswL9MW4Pa5nbc+fYmPLNwB5aU1XlzCyfVulZzZ28ZIhrU43O3Y9bmfbjwKyeivSsBAEhobkk9l7IM+cOWO1EBau3ogvZL0GU1LSgaPxMfb9nfZ3rjoU4AwD3vb8HyHfWh7D+Xsowp7kSaxOROFEONhzpR09yWdl59SztG/W42nk65arSzO4EfPPYJAGB6cWXG7XZ0J8IN1DCXDi5BMbkTxcCS0jp0pSTeb90/DxdMmJd22f1NyStG39+QvNBo+/7mlBp6frhYlnEn0iTW3IkcsnlvI1o7unF+0Ym901bsrMdPJ63Ev138l/jNZV8FALR2dPve5mWPLwo9Tr+yaTmHmWSDHFxca+Oz5U5ksanLKlBW09z7/Id/XIIfP7u8zzK1zcmW+M66g4G3P1gJJkqSQ4Z2LcmawpY7kYW272/GlKXleG1VJY4eMQxb77si9H2oAre9uTH07frdN+BWWcY1bLkTWWDCzC244+1Nvc/HvVSM11YlW9WHOv2XWDKpbW7HFX9Y1OeiozC2myvTZRkb9hvVdpnciQy79tnleH5xOV5btTuyfby6cjdK9jXjjdXR7SMIF8syUe03qu0yuRMZtK+xDasqGiLbfkt78lZ2G6uSg3qN8m5MDZjtBsiyTPSGTO4iMllEakTk05Rp94jIHhFZ7/1clTLvDhEpE5FtInJ5VIETua6tsxsX3p++u2JYek6+tnUlSzDDPmdXe45lmej4+Uu/CCDd2ZzHVfU87+dDABCRUQDGAjjXW+dpERkWVrBEcdHU1okn55dFvp+t1cmx1W1rIbtYlnHNkL1lVHWRiBT53N7VAF5X1XYA5SJSBuACAMsHX42osNwweVVexz9P10LOaXiYHDOsi2UZ1w4quXxHu0VENnplmxO8aacBSO04W+VNG0BExolIsYgU19bW5hAGkd3eWlM1oD95lIm9p76eTv/xZAodhx8Y6BkAZwM4D0A1gEe96ekOw2nfPVWdqKqjVXX0yJEjswyDyH6/+fOGvPYn/9GTS30tl1Oez7HBnUtZxhTXQs4quavqflXtVtUEgOeRLL0AyZb6GSmLng5g8DvlEsXYzyavCm1b50/4OLRtmWbLFwgOP9CPiJya8vR/AejpSfMegLEicqSInAXgHADh/XcTOaStsxuLtodXcuwZZiAbLtW2KRxDnlAVkdcAjAFwkohUAbgbwBgROQ/Jg1kFgH8GAFXdLCLTAWwB0AXgZlU1fxkckQH/+OyytNN31QcfAyZXttWWcynL8DDlj5/eMj9JM3nSIMtPADAhl6CIXLex6gA+3dM0YLqq4nsPL8x/QL37tyPR51KWMRW9awcVu65oIIqJdCc1pywtx+6GVgPRUBjMHxKD4aiQRCFSVTw4a1vaeb9/fwtWRzjUgB8K7a2/59QtMsdMx7JM9NhyJwpRyb5mPPvJjozzC/HEpqTJ5C6WZVzD5E4UoiufWGw6BN9ySpIBjlFxuXDKtSF/WZYhCkF3QrGjtmXoBQ0LLc+GVJax4eSuX64N+cvkThSCbz84H9WNbabDyMi2clBMGvNWY1mGKEdPfFzqO7GbaqmGPnBYSMcK2w46g3En0iQmd6IcLC2rw+Mfbzcdhm8sy2Qvqkh5mz0iC904tTjQ8ixHJPF9OIy32SOySGtHF342eZUVN5kOQvs8ziGtxKQs49I3h6B4QpUooEXba7Me7dFUi9V0Es3EpeRq5zuYGZM7UT8t7V04esQwDPvc4Y/zoY5ufO13swAAf336X5gKLWuhn1CNCQ75S1Qg2ru68fW7Z+OBj7b2mV68y+ywAWHxc0GRryQWUqaz9RvFYFyJmMmdKMWyHfUAgHklNb3TVBXXTwrntgQulSHywcX3w5WImdyJUvxiymoAwFHDh/VOm7Sk3FQ4wQTMOpkW99UyDTL8gP9FfTHVcnalxd6DNXciT2Wa4XifWlCGh2enH+UxG6br3KHt3mBZxtRb6EqLvQdb7kSea54aOAZ7mIk9cq41LeFmWcYVTO5U8Er3N+PSxz5B/cGOPtMbWzvTLm+69Z2TlNjzNfyA0++Xw5jcqeBN+HArSmv6jui4u6EV37h3Tuj7MneLuMPZOJTWcgH3lgkbhx8gikDjoU58sr12wPSW9q6M67hYSkgfs/nX4eJ7GTYO+UsUgW/8PvzW+WBMlyhSb7OXk0CbsD+Bx/EbBFvuVFCa2zrxzrqqnLZhOkFbwXsPcn0vbEmqfr5B2BGpf2y5U0H5p5eKsWJnAy4464s47fijDUQQ4ZHBx6Y1rBOqIXGpLOPakL9M7lQQGg914t73t2DFzuQwAq61wvIp7CRmw0EkTGH/73DIX6IcPDJ7G95ae7gck8sHytpkZeCIletbYbosk803B1v//P0xuVNBmLZiV5/nFz0wH2t2fZb3OEwfGDTD41RhDz8wGJfKMq5922Nyp9ibvXlfoOlDcScdRSjACVWb3y8bhvxlP3eiLP3ztDVppx93VP5POdmc6EwwXZbJBmvuRBbYc+BQ6Nv0Mya6rfr2ljF/mz2XyjI9XImYvWUotirqDuKh2SWmw7BOmMMP+NmWw8fCvGBXSKKAxjyy0HQIA5hu9acmYxtyrotlmbCxLEMUwM7alqEXKlD5H34gM1vKMnE8yDC5Uyxc++xyPJxSgnliXmlk+8ql8W1HKgtBoN4y9r9qF2IMismdnNXW2Y2W9i50dSewqqIBTy3YYTqkIUValXFw+IE4tpiDYs2dqJ///ttZAICS+64YMG/G+r35Dic28pnzXWwxx6YrpIhMFpEaEfk0ZdqJIjJXREq93yekzLtDRMpEZJuIXB5R3FRgtuxtQnndQdQ0taG4oiHt/U7zxdqEZOnwAzZ8Q8gkzsMP+Gm5vwjgSQAvpUwbD2Ceqj4gIuO957eLyCgAYwGcC+BLAD4Wkb9S1e5ww6ZC0NGVwEvLK/DzvyvCVX9c3Gfe+7d820xQjusz/ECGrJvPYwTLMtEZMrmr6iIRKeo3+WoAY7zHUwEsBHC7N/11VW0HUC4iZQAuALA8nHDJJcvK6rC7oRVjLzgzq/V/NnklVuxswIhhg3/BzHfLkCdUgxnsNZv+FhRo+IGIQrWt5n6KqlYDgKpWi8jJ3vTTAKxIWa7KmzaAiIwDMA4Azjwzuw8/2WtfYxuue2ElAGSV3JeV1fUOz7t8R/2gy5pOEE4JOUOZ7rcfliBJPjY194DSve60savqRFUdraqjR44cGXIYZNr9H20ddP49723Gz6esyjj/p5NW9j6eleUAX1HJbbhge5JhTpGElOFMl2V6GgZBGgj2/AUHl23Lfb+InOq12k8FUONNrwJwRspypwNgt4UC0p1QHOzo6tNbpb2rG1f+YTGOPWo4Zni18heXVQy6nUSAT5BF+dIJYQ4/4GvRQf5A2cbynYfm46QvHIl3/vWirNbPjlv/aNkm9/cA3ADgAe/3jJTpr4rIY0ieUD0HQObmGcXOra+vwwcbq/tMu+TRT1D1mf8BvA515Of8u0h2rUabWt99BB1+18KXUVF30NdylQ2HUNmQ+6Bwpr85JGOIhp+ukK8heUL0qyJSJSK/QjKpXyoipQAu9Z5DVTcDmA5gC4BZAG5mT5l4UlUsKKlBol8Tu39iBxAosde3tONv/2tusFgCLZ2ynq1JOmJDJTRf70qAjNTS3uU7FlPjAZlM8lH9F/rpLfOTDLMuybD8BAATcgmK7Nbe1Y3//dwKrK88gPuu+Tquv/DLAIY+8ZnO1uom7Gtqw/e/mjwnf83TS9Gap5Z7tqw9JPjIT6EdzwIMP3DXO59mnGfLyXBb4ggTr1ClwB6dsx3rKw8AAPZ646V3difwyxdXB97WlU8k+69XPPBDAMjqq3beW+C5dIW0KIfkdJu9AuRaV0iOLUOBTVy0c8C0d9buwaFOMy3uvOfLmGe/fL6fNtS8g3IlYrbcKZC2fgm8+sAhfP+RhfjmmccbisiAnC5iym7lsL6dhP0tJ9dyhi3lEJP3UjVWcyfqUdvcjvMnfNxn2rtel8fdJsd6sSM/WCu199FnrZ29QznYMPxANhZtrw19m7YcZMLE5E6+vbB4YDmmxwnHHIG6lvYht3GgtSNQH3Yb5XYRU37XA4Cv/W5W7+MdKTcxseHP4FJZJqr3y7bhB6iA7Ko/iK3VTXguTa09qPPuDdbN0RcbspQNgvZzD2OXQ2ywf1fZAetb8seL4/ADTO40KFXF9x5eaDqMAUwmhULtH59qUWktzh75hSGXm7ZiVx6iyV6chx9gbxka1C+y6N6Yb7a0/vzIuizjZyE/TcqQ3qopSyvw3YcXDLncrvrBz8U4VZZx598MAJM7DaKmqQ0Lt4V/8ioMcbyiMN/CSFa5bsP0gdmGgwtr7pRXew4cwrcfnG86DF9calGZ7grpa1/e78qGVnznoaFb53EQx5o7W+6U1qNztgVMmgZr4P2ed0fcHcelg0l/qQeXoS46m7Sk3Mf2so8EsKPlDLDmTgXgYHsXKhta8fbaPYHWq2vpiCii9OoPZu52efadH0a671xKCWEdGLq6E9jf1BbOxvrpSbftXdFfcWy6LBOEayfSWZahPs69e7bpEHz5+ZTDJ3rz/aEz0dpsPNTZ5/k972/Gyyt2Y8Pdl4W+r553Mx9vq2P5EkD4ZRnW3ClyJfuaTIfghChbm6vKG3DKcUcOmH7tc31vQzxva/L+OAdThtPd1zh0Sz5IMvWzbLYH1p7VshxSP3QcfoBiK5FQXPGHxabDyIpLjb+hYu1J4kVfPKbP9B21fW9iUZ0mka/Z9VlOsfXoSXPZHsRSE+VQ27Cl5e5Secgv1twJADC/pGbohQiAPQkpG3kptcTw5CTg3vADTO6EmRurceNLxabDyJpTydahWH2VZYaYn6ncob3z3eNKzCzLFLDKhlZc/OhCdHY7lHHSyPdXaqcOJjnIx8s0/Vb2Dj8Q5FxE6DFEgy33Avan+aXOJ/ZcZHuD7Fz4PRB1R3QECVQyYW+ZPlyKFWByL1iLS2sxvbjKdBjhyHoYXXs/rdncbtCIHN97071lbLiIijV3CtVgNy2mwe054EjiTSNIHT0f5S6Lj68ZmT8c+MPkXoD2NbYZvXNS2LLNDybu+RpFMous9WtZz5oo9x8kCldq7jyhWkAWlNSg/mAHTj524EUyheipBTtMhxCKsA8Yh/u5+9h3tgOh9e7LlXaw+QNRUEzuMff0wjIAwL+O+UsnxmbPRmpyu+udTeYC8aE4pAuNsuUvYeeP6Zuu2HBw4fADFIiqYswjC3tvlnDT9842HFF0KuoPX735ysrdBiOJl7yccHarMQyAQ/6SQaqKDVWNfe6C89DsbQYjGlrR+JlZrzt24ooQI6FAZZkcb/jdkjI2Tjbu+2BLTuv3CHIgc+V4xJZ7DD0wqwTPfdL3ZtbPLIxHfZlyY1vvlFy/afkZcz6TwO9FRO8du0KSLzVNbQMSO1E2whh+wLWTkH6Yr9L7w+TusOa2Try0vKLPV8oL/t88cwGRETM3VgdY2o7yg80XkA2FXSEpcre+vh7zS2pwftGJ+Nqpx2FZWZ3pkMiAWZv3RbLdMBKwDb1R/LCtF1EY2HJ3wPTiygE18521Lb3D9I4YlvwzXvfCyrzHRoVtqPyfqSxjQ6K0IQaAXSELVmtHF257cyMA4KYxye6MiYTi4kc/SVnKln9Tsl2w4Qey40prPVuuvDq23C3QeKgTReNn4t11A29KXbq/pfdxV3cCALCr39ABP3hsEW57c0O0QZKVojqsX/f8ioC1/MNSW+u2J/reWDnkL4Wtvasb76xNjs745zWVvdNbO7pQ3dh3gKp/8m6ocefbA6/CjM0IjxRI0Lq4n6X3NbZh2Y56n9vLtqN7dquFKfB7Z0HMQbAsY9gvX1yNpWXJD9KxR44AANQ2t+P8CR8DAGbcfFHvsgu21QIAlu/098Gj+AuacPwktE17GrOMJslPa92WPGnDNwsra+4iUgGgGUA3gC5VHS0iJwJ4A0ARgAoA16qq2QE1LLKqvAFHjxiG/3H6XwBAb2IHgNKaZiwurcX1k1ZlXH+5zxYVFYaEhc3JOPZtT2X+cOBPGGWZ76vqeao62ns+HsA8VT0HwDzvOXmufW45/ueTS9LO21F7cNDEDgA/eZ6X2tNhpnN79sMP2HEAODzkr7n+/y71c78awBjv8VQACwHcHsF+nPLC4p34eOt+02FQzARtuecjpbpSlgk++oANUfuXa3JXAHNERAE8p6oTAZyiqtUAoKrVInJyuhVFZByAcQBw5pln5hiGvR6fux2tHV14fnH2Y2AQZZIIXHOPJo4++3AoCWZTcw+7LGNlzR3ARaq610vgc0WkxO+K3oFgIgCMHj3anf+GAFo7uvDEvFLTYVCMRdFbJh/bs6QqE2s51dxVda/3uwbAOwAuALBfRE4FAO93Ta5BuqatsxtrdjVg1O9mD7qcLXVHclfg0kIe/udSd5H5ClW7/vd9XdwVvEu8UVm33EXk8wA+p6rN3uPLANwL4D0ANwB4wPs9I4xAXbGjtgWX9Ll6NL3KhlY8OsfuMdbJfoFr7qE33V1JdQM5HLovuZRlTgHwjiTvzjscwKuqOktEVgOYLiK/ArAbwI9zD9MdfhI7AHznoQURR+IefpMJLpEItny+W8yZatou/6ld6QqZdXJX1Z0AvpFmej2AS3IJylVPzmd9PRcryxtMh+Ac4y33IfZh88BhQEpXyBgOP8ArVENy94xPMXX5LtNhOK3pUKfpEGIv7ORuS5LORtBvMa69Vo4tExImdjIhaMs913uWBpWxq6ElmdKG4QeiwuSeo01VjTnd3JkoF0H7uec6bowf2uexG71lgnDlcMDknoOu7gRuf2tjpPsQV/6TyAjTY8u4fGIUSB1+IMg6IccQ0XvI5J6DW19fjy3VTZHuw/UPD0XL9v8Pm3vLRDGiZnai2S6Te5bqWtoxc1N2NzMIwoLPQN5MW8HzFkHZ2H3UT0y2RG3D8ANRFXqY3LM0+r8+zst+bPzwRmVxKW/wHVTQmnvYhvr/dLm27jom9yzUNLflbV+mP7xkt/41955bMdrOlkbL4X7u/r9t+I3c/2tkWcYaN04tzuPe7PgQkJ365495JeaHckoNKWPNPT+hOCGq4xwvYgrgT/NKsaSsDhurou9O1sOSBg5Zqn/rsL6lI7/7H3K+3f/ANtTco+oRx+QewKNzt+d9n//47PK875Pc0b9s50rXWTZaoseyjE+Tl/BmG2SfvQcOGd1/uiSdOs3mK0D7joHjZ4UAy8L/AYz93A16f8Ne3PvBFtNhEA1wW7+L6GxrEdtelokzJvchzC/Zj397bZ3pMIjIEvZ+F+mLNfcMDrR24Il5pZiytMJ0KETWGmpAX5vLMoAdQ/5Ghck9g9/O2Iz3N+w1HQZRILadULW5LBN8yN9ohgjmeO55smbXZ/j1G+tQ2WD2RBVRNmyrudvOhq6QUWHNvZ9/f2M9Ezs5K98t5XRXYbrSWybu2HL3JBKK+SU12N3QajoUoqzZ1nK3uSwDpMbnY/iBwF0h/S0Z1VAMTO6eez/YgheXVZgOgygnNozZYj4Cfyx4qwBE936xLANgVXkDEzvFAgeaC8aGmntUhauCT+4dXQlc+xwv8ad4sKHlnoo1d3MKOrl/sHEv/uo/PzIdBlFoui3I7X0v67cgoAz63OvVR5iBa+4hLxdUQSf3W17llacUL4k812Us+6JAKQryhOrTC8vwp3llpsMgCl2XZUX3OJZlXHlFBZfcZ6zfg4dmbTMdBlEkuhP5vRNTurJL6jSbyzLZcuUVFVRy/893N+HlFbtNh0EUGUfusmeF1JPPfhJ20KTOIX/z5KNN1UzsFHv5brkPhWUZc2Lfct/X2IZ/eGYZ9hi+qQFRPnTn+QznUDfriGNZxhWxTu7TV1cOuJkBUZzZdkLVZopgQ/72lHH8d3E0+7eIbVmmoyvBxE4Fp9uGju4UCMeW8Wl1RQN+zJtKU4HKe1nG5zRb2TD8QFRik9zL6w7i+48sNB0GkVHdLMuQx/nk3tGV4BACRB7W3P1TTam5+xnyt99vP9s3yfmaOxM70WH5rrmn7y3DA0wQzo0tIyJXiMg2ESkTkfFR7YeIDst3zd11ca65R5LcRWQYgKcAXAlgFICfiMiosPdTNH5m2Jskclq+Bw4je0kUX6FE5FsA7lHVy73ndwCAqt6fbvnRo0drcXFx4P0wuROR6449ajg23XN5VuuKyBpVHZ1uXlRlmdMAVKY8r/KmpQY1TkSKRaS4trY2ojCIiOz24D/8dSTbjaq3TLqyVJ+vCKo6EcBEINlyz2YnFQ/8MJvViIhiL6qWexWAM1Kenw5gb0T7IiKifqJK7qsBnCMiZ4nIEQDGAngvon0REVE/kZRlVLVLRG4BMBvAMACTVXVzFPsiIqKBIrtCVVU/BPBhVNsnIqLMnL9ClYiIBmJyJyKKISZ3IqIYYnInIoqhSIYfCByESC2AXVmufhKAuhDDiQJjDAdjDAdjDIcNMX5ZVUemm2FFcs+FiBRnGlvBFowxHIwxHIwxHLbHyLIMEVEMMbkTEcVQHJL7RNMB+MAYw8EYw8EYw2F1jM7X3ImIaKA4tNyJiKgfJnciohhyOrnbcBNuETlDRBaIyFYR2Swit3rTTxSRuSJS6v0+IWWdO7yYt4lIdvfXyi7WYSKyTkQ+sDFGETleRN4UkRLv/fyWhTH+u/d3/lREXhORo0zHKCKTRaRGRD5NmRY4JhH5WxHZ5M37o4iEdi/oDDE+7P2tN4rIOyJyvG0xpsz7vyKiInKSyRgDUVUnf5AcSngHgK8AOALABgCjDMRxKoC/8R4fC2A7kjcFfwjAeG/6eAAPeo9HebEeCeAs7zUMy1Os/wHgVRXRK4cAAAOFSURBVAAfeM+tihHAVAA3eo+PAHC8TTEieavIcgBHe8+nA/i56RgBfBfA3wD4NGVa4JgArALwLSTvpPYRgCsjjvEyAMO9xw/aGKM3/Qwkhy/fBeAkkzEG+XG55X4BgDJV3amqHQBeB3B1voNQ1WpVXes9bgawFckkcDWSyQre72u8x1cDeF1V21W1HEAZkq8lUiJyOoAfAnghZbI1MYrIcUh+uCYBgKp2qOoBm2L0DAdwtIgMB3AMkncYMxqjqi4C0NBvcqCYRORUAMep6nJNZqiXUtaJJEZVnaOqXd7TFUjesc2qGD2PA7gNfW8VaiTGIFxO7kPehDvfRKQIwDcBrARwiqpWA8kDAICTvcVMxf0HJP9BEynTbIrxKwBqAUzxSkcviMjnbYpRVfcAeATAbgDVABpVdY5NMaYIGtNp3uP+0/Pll0i2cgGLYhSRHwHYo6ob+s2yJsZMXE7uQ96EO59E5AsA3gLwa1VtGmzRNNMijVtE/h5Ajaqu8btKmmlRv7fDkfxK/IyqfhPAQSTLCZmYeB9PQLLFdhaALwH4vIj8dLBV0kwz3fc4U0zGYhWRuwB0AXilZ1KGWPIao4gcA+AuAL9LNztDLNb8zV1O7tbchFtERiCZ2F9R1be9yfu9r2jwftd4003EfRGAH4lIBZLlq4tF5GXLYqwCUKWqK73nbyKZ7G2K8QcAylW1VlU7AbwN4O8si7FH0JiqcLgskjo9UiJyA4C/B/B/vDKGTTGejeSBfIP32TkdwFoR+W8WxZiRy8ndiptwe2fCJwHYqqqPpcx6D8AN3uMbAMxImT5WRI4UkbMAnIPkCZjIqOodqnq6qhYh+T7NV9WfWhbjPgCVIvJVb9IlALbYFCOS5ZgLReQY7+9+CZLnWGyKsUegmLzSTbOIXOi9tp+lrBMJEbkCwO0AfqSqrf1iNx6jqm5S1ZNVtcj77FQh2Xliny0xDvUCnP0BcBWSvVN2ALjLUAzfRvJr10YA672fqwB8EcA8AKXe7xNT1rnLi3kb8nwmHcAYHO4tY1WMAM4DUOy9l+8COMHCGH8PoATApwCmIdlbwmiMAF5D8hxAJ5IJ6FfZxARgtPe6dgB4Et4V7BHGWIZk3brnc/OsbTH2m18Br7eMqRiD/HD4ASKiGHK5LENERBkwuRMRxRCTOxFRDDG5ExHFEJM7EVEMMbkTEcUQkzsRUQz9f2U9ZJX54Y/3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_epochs,all_penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
